# CoR-GS Stage 2 - Co-Pruning å®ç°æ–¹æ¡ˆ

## æ ¸å¿ƒç­–ç•¥ (3-5 å¥æ€»ç»“)

é‡‡ç”¨æ¸è¿›å¼é›†æˆç­–ç•¥ï¼Œåœ¨ç°æœ‰ Stage 1 Disagreement Metrics åŸºç¡€ä¸Šæ·»åŠ  KNN åŒå‘å‰ªææœºåˆ¶ã€‚æ ¸å¿ƒä¿®æ”¹é›†ä¸­åœ¨ `train.py` è®­ç»ƒå¾ªç¯å’Œæ–°å»º `copruning.py` å·¥å…·æ¨¡å—ï¼Œé€šè¿‡ `--enable_copruning` å¼€å…³å®ç°å‘ä¸‹å…¼å®¹ã€‚å®æ–½è·¯çº¿åˆ† 3 å¤©ï¼šDay 1 æ ¸å¿ƒç®—æ³•å®ç° + å•å…ƒæµ‹è¯•ï¼ŒDay 2 è®­ç»ƒé›†æˆ + æ—¥å¿—ç›‘æ§ï¼ŒDay 3 å®éªŒéªŒè¯ + å‚æ•°è°ƒä¼˜ã€‚é¢„æœŸåœ¨ Foot 3-views æ•°æ®é›†ä¸Šè¾¾åˆ° PSNR â‰¥28.5 dB (ç›®æ ‡è¶…è¶Š baseline 28.547 dB)ã€‚

---

## ğŸ“ æ–‡ä»¶ä¿®æ”¹è¯¦ç»†æ–¹æ¡ˆ

### ä¿®æ”¹ 1: æ–°å»ºæ ¸å¿ƒæ¨¡å— `r2_gaussian/utils/copruning.py`

**æ–‡ä»¶è·¯å¾„**: `/home/qyhu/Documents/r2_ours/r2_gaussian/r2_gaussian/utils/copruning.py`

**åŠŸèƒ½**: Co-pruning åŒå‘å‰ªæç®—æ³•å®ç°

**å®Œæ•´ä»£ç ** (150 è¡Œ):

```python
"""
CoR-GS Stage 2: Co-Pruning Module

Paper Reference:
- CoR-GS: Sparse-View 3D Gaussian Splatting via Co-Regularization
- Section 4.1: Co-pruning
- Formula 1-2: KNN matching and non-matching mask computation

Author: @3dgs-research-expert
Date: 2025-11-17
Version: 1.0
"""

import torch
import torch.nn as nn
from pytorch3d.ops import knn_points


class CoPruningModule:
    """
    Co-Pruning æœºåˆ¶å®ç°ç±»

    æ ¸å¿ƒç®—æ³•:
    1. KNN åŒå‘åŒ¹é…: f(Î¸_i^1) = KNN(Î¸_i^1, Î˜^2)
    2. è·ç¦»åˆ¤æ–­: M_i = 1 if ||Î¸_i^1 - f(Î¸_i^1)|| > Ï„
    3. åŒå‘å‰ªæ: åŒæ—¶ç§»é™¤ä¸¤ä¾§çš„éåŒ¹é…ç‚¹
    """

    def __init__(self, tau=5.0, device='cuda'):
        """
        åˆå§‹åŒ– Co-Pruning æ¨¡å—

        Args:
            tau (float): è·ç¦»é˜ˆå€¼ï¼Œé»˜è®¤ 5.0 (é’ˆå¯¹ [-1,1]Â³ å½’ä¸€åŒ–åœºæ™¯)
            device (str): è®¡ç®—è®¾å¤‡
        """
        self.tau = tau
        self.device = device

        # ç»Ÿè®¡ä¿¡æ¯
        self.stats = {
            'total_prunings': 0,
            'total_points_removed_1': 0,
            'total_points_removed_2': 0,
            'avg_removal_rate_1': 0.0,
            'avg_removal_rate_2': 0.0
        }

    def __call__(self, gaussian_model_1, gaussian_model_2):
        """
        æ‰§è¡Œ Co-Pruning å‰ªæ

        Args:
            gaussian_model_1: GaussianModel instance (æ¨¡å‹ 1)
            gaussian_model_2: GaussianModel instance (æ¨¡å‹ 2)

        Returns:
            tuple: (pruned_model_1, pruned_model_2, pruning_info)
        """
        return self.co_prune(gaussian_model_1, gaussian_model_2)

    def co_prune(self, gaussian_model_1, gaussian_model_2):
        """
        Co-Pruning æ ¸å¿ƒç®—æ³•

        å®ç°æ­¥éª¤:
        1. æå–ä¸¤ä¸ªæ¨¡å‹çš„ 3D ä½ç½®
        2. KNN æœç´¢æ‰¾åˆ°æœ€è¿‘é‚»
        3. è®¡ç®—æ¬§å‡ é‡Œå¾—è·ç¦»
        4. ç”ŸæˆåŒ¹é…æ©ç  (dist <= tau)
        5. åŒå‘å‰ªæ

        Returns:
            tuple: (pruned_model_1, pruned_model_2, info_dict)
        """

        # Step 1: æå– 3D ä½ç½®
        xyz_1 = gaussian_model_1.get_xyz  # [N1, 3]
        xyz_2 = gaussian_model_2.get_xyz  # [N2, 3]

        num_before_1 = xyz_1.shape[0]
        num_before_2 = xyz_2.shape[0]

        # Step 2: KNN æœç´¢ (ä½¿ç”¨ PyTorch3D ä¼˜åŒ–å®ç°)
        # knn_points è¿”å›: (dists, idx, nn)
        # dists: æœ€è¿‘é‚»è·ç¦»çš„å¹³æ–¹ [batch, N, K]
        knn_result_1to2 = knn_points(
            xyz_1.unsqueeze(0).to(self.device),  # [1, N1, 3]
            xyz_2.unsqueeze(0).to(self.device),  # [1, N2, 3]
            K=1,  # åªæ‰¾æœ€è¿‘é‚»
            return_nn=False
        )

        knn_result_2to1 = knn_points(
            xyz_2.unsqueeze(0).to(self.device),
            xyz_1.unsqueeze(0).to(self.device),
            K=1,
            return_nn=False
        )

        # Step 3: è®¡ç®—æ¬§å‡ é‡Œå¾—è·ç¦» (knn_points è¿”å›å¹³æ–¹è·ç¦»)
        dist_1 = torch.sqrt(knn_result_1to2.dists.squeeze(0).squeeze(-1))  # [N1]
        dist_2 = torch.sqrt(knn_result_2to1.dists.squeeze(0).squeeze(-1))  # [N2]

        # Step 4: ç”ŸæˆåŒ¹é…æ©ç  (ä¿ç•™ dist <= tau çš„ç‚¹)
        # è®ºæ–‡å…¬å¼: M_i = 0 if dist <= tau, else 1
        # è¿™é‡Œåè½¬: mask_keep = True è¡¨ç¤ºä¿ç•™
        mask_keep_1 = dist_1 <= self.tau
        mask_keep_2 = dist_2 <= self.tau

        # Step 5: å‰ªææ“ä½œ
        gaussian_model_1.prune_points(mask_keep_1)
        gaussian_model_2.prune_points(mask_keep_2)

        num_after_1 = gaussian_model_1.get_xyz.shape[0]
        num_after_2 = gaussian_model_2.get_xyz.shape[0]

        # Step 6: ç»Ÿè®¡ä¿¡æ¯
        num_removed_1 = num_before_1 - num_after_1
        num_removed_2 = num_before_2 - num_after_2

        removal_rate_1 = num_removed_1 / num_before_1 * 100 if num_before_1 > 0 else 0
        removal_rate_2 = num_removed_2 / num_before_2 * 100 if num_before_2 > 0 else 0

        # æ›´æ–°å…¨å±€ç»Ÿè®¡
        self.stats['total_prunings'] += 1
        self.stats['total_points_removed_1'] += num_removed_1
        self.stats['total_points_removed_2'] += num_removed_2
        self.stats['avg_removal_rate_1'] = (
            self.stats['avg_removal_rate_1'] * (self.stats['total_prunings'] - 1) +
            removal_rate_1
        ) / self.stats['total_prunings']
        self.stats['avg_removal_rate_2'] = (
            self.stats['avg_removal_rate_2'] * (self.stats['total_prunings'] - 1) +
            removal_rate_2
        ) / self.stats['total_prunings']

        # è¿”å›è¯¦ç»†ä¿¡æ¯
        info = {
            'num_before_1': num_before_1,
            'num_after_1': num_after_1,
            'num_removed_1': num_removed_1,
            'removal_rate_1': removal_rate_1,

            'num_before_2': num_before_2,
            'num_after_2': num_after_2,
            'num_removed_2': num_removed_2,
            'removal_rate_2': removal_rate_2,

            'mean_dist_1': dist_1.mean().item(),
            'mean_dist_2': dist_2.mean().item(),
            'max_dist_1': dist_1.max().item(),
            'max_dist_2': dist_2.max().item()
        }

        return gaussian_model_1, gaussian_model_2, info

    def get_stats(self):
        """è¿”å›ç´¯è®¡ç»Ÿè®¡ä¿¡æ¯"""
        return self.stats

    def reset_stats(self):
        """é‡ç½®ç»Ÿè®¡ä¿¡æ¯"""
        self.stats = {
            'total_prunings': 0,
            'total_points_removed_1': 0,
            'total_points_removed_2': 0,
            'avg_removal_rate_1': 0.0,
            'avg_removal_rate_2': 0.0
        }


# ========== è¾…åŠ©å‡½æ•° ==========

def compute_point_rmse(gaussian_model_1, gaussian_model_2, device='cuda'):
    """
    è®¡ç®—ä¸¤ä¸ªæ¨¡å‹çš„ç‚¹äº‘ RMSE (ç”¨äº Disagreement Metrics)

    Args:
        gaussian_model_1: GaussianModel instance
        gaussian_model_2: GaussianModel instance
        device: è®¡ç®—è®¾å¤‡

    Returns:
        dict: {'rmse': float, 'fitness': float, 'mean_dist': float}
    """
    xyz_1 = gaussian_model_1.get_xyz
    xyz_2 = gaussian_model_2.get_xyz

    # KNN æœç´¢
    knn_result = knn_points(
        xyz_1.unsqueeze(0).to(device),
        xyz_2.unsqueeze(0).to(device),
        K=1,
        return_nn=False
    )

    dists = torch.sqrt(knn_result.dists.squeeze(0).squeeze(-1))

    # RMSE: å‡æ–¹æ ¹è¯¯å·®
    rmse = torch.sqrt(torch.mean(dists ** 2)).item()

    # Fitness: tau=5.0 å†…çš„åŒ¹é…ç‚¹æ¯”ä¾‹
    tau = 5.0
    fitness = (dists <= tau).float().mean().item()

    # Mean distance: å¹³å‡è·ç¦»
    mean_dist = dists.mean().item()

    return {
        'rmse': rmse,
        'fitness': fitness,
        'mean_dist': mean_dist,
        'max_dist': dists.max().item(),
        'min_dist': dists.min().item()
    }
```

---

### ä¿®æ”¹ 2: è®­ç»ƒè„šæœ¬é›†æˆ `train.py`

**æ–‡ä»¶è·¯å¾„**: `/home/qyhu/Documents/r2_ours/r2_gaussian/train.py`

**ä¿®æ”¹ä½ç½® 1: å¯¼å…¥æ¨¡å— (Line ~15)**

```python
# åœ¨ç°æœ‰ imports åæ·»åŠ 
from r2_gaussian.utils.copruning import CoPruningModule
```

---

**ä¿®æ”¹ä½ç½® 2: å‘½ä»¤è¡Œå‚æ•° (Line ~350, ArgumentParser section)**

```python
# CoR-GS Stage 2: Co-Pruning Parameters
parser.add_argument('--enable_copruning', action='store_true',
                    help='Enable CoR-GS Stage 2 Co-Pruning mechanism')
parser.add_argument('--copruning_interval', type=int, default=5,
                    help='Execute co-pruning every N densification steps (default: 5)')
parser.add_argument('--copruning_tau', type=float, default=5.0,
                    help='Distance threshold for co-pruning (default: 5.0 for normalized scenes)')
```

---

**ä¿®æ”¹ä½ç½® 3: åˆå§‹åŒ– Co-Pruning æ¨¡å— (Line ~200, training() å‡½æ•°å¼€å¤´)**

```python
def training(dataset, opt, pipe, gaussians, scene, testing_iterations, saving_iterations):
    ...

    # ===== æ–°å¢: åˆå§‹åŒ– Co-Pruning æ¨¡å— =====
    copruning_module = None
    densification_step_counter = 0

    if len(gaussians) == 2 and opt.enable_copruning:
        copruning_module = CoPruningModule(
            tau=opt.copruning_tau,
            device=dataset.device
        )
        print(f"[CoR-GS Stage 2] Co-Pruning enabled with tau={opt.copruning_tau}, "
              f"interval={opt.copruning_interval}")
    elif opt.enable_copruning:
        print("[Warning] Co-Pruning requires --gaussiansN 2, but got",
              len(gaussians), "models. Co-Pruning disabled.")
    # =========================================

    first_iter = 0
    ...
```

---

**ä¿®æ”¹ä½ç½® 4: Densification å¾ªç¯ä¸­è§¦å‘ Co-Pruning (Line ~300)**

**åŸå§‹ä»£ç :**
```python
# ç°æœ‰ densification é€»è¾‘ (å¤§çº¦åœ¨ Line 300-320)
if iteration >= opt.densify_from_iter and iteration <= opt.densify_until_iter:
    if iteration % opt.densification_interval == 0:
        for gaussian in gaussians:
            size_threshold = 20 if iteration > opt.opacity_reset_interval else None
            gaussian.densify_and_prune(
                opt.densify_grad_threshold,
                0.005,
                scene.cameras_extent,
                size_threshold
            )
```

**ä¿®æ”¹å:**
```python
if iteration >= opt.densify_from_iter and iteration <= opt.densify_until_iter:
    if iteration % opt.densification_interval == 0:
        densification_step_counter += 1  # âœ¨ æ–°å¢è®¡æ•°å™¨

        # åŸå§‹ densification é€»è¾‘
        for gaussian in gaussians:
            size_threshold = 20 if iteration > opt.opacity_reset_interval else None
            gaussian.densify_and_prune(
                opt.densify_grad_threshold,
                0.005,
                scene.cameras_extent,
                size_threshold
            )

        # ===== æ–°å¢: Co-Pruning è§¦å‘é€»è¾‘ =====
        if copruning_module is not None:
            if densification_step_counter % opt.copruning_interval == 0:
                print(f"\n[Iteration {iteration}] Executing Co-Pruning...")

                # æ‰§è¡Œ Co-Pruning
                gaussians[0], gaussians[1], pruning_info = copruning_module(
                    gaussians[0],
                    gaussians[1]
                )

                # è¯¦ç»†æ—¥å¿—è¾“å‡º
                print(f"  Model 1: {pruning_info['num_before_1']} â†’ "
                      f"{pruning_info['num_after_1']} pts "
                      f"({pruning_info['num_removed_1']} removed, "
                      f"{pruning_info['removal_rate_1']:.2f}%)")
                print(f"  Model 2: {pruning_info['num_before_2']} â†’ "
                      f"{pruning_info['num_after_2']} pts "
                      f"({pruning_info['num_removed_2']} removed, "
                      f"{pruning_info['removal_rate_2']:.2f}%)")
                print(f"  Mean Distance: Model1={pruning_info['mean_dist_1']:.6f}, "
                      f"Model2={pruning_info['mean_dist_2']:.6f}")

                # (å¯é€‰) TensorBoard è®°å½•
                if tb_writer:
                    tb_writer.add_scalar(
                        'copruning/num_points_model1',
                        pruning_info['num_after_1'],
                        iteration
                    )
                    tb_writer.add_scalar(
                        'copruning/num_points_model2',
                        pruning_info['num_after_2'],
                        iteration
                    )
                    tb_writer.add_scalar(
                        'copruning/removal_rate_model1',
                        pruning_info['removal_rate_1'],
                        iteration
                    )
        # =======================================
```

---

### ä¿®æ”¹ 3: éªŒè¯ GaussianModel æ”¯æŒ (å¯é€‰)

**æ–‡ä»¶**: `/home/qyhu/Documents/r2_ours/r2_gaussian/r2_gaussian/gaussian/gaussian_model.py`

**æ£€æŸ¥æ˜¯å¦å­˜åœ¨ `prune_points()` æ–¹æ³•:**

å¦‚æœä¸å­˜åœ¨ï¼Œéœ€è¦æ·»åŠ è¯¥æ–¹æ³• (å‚è€ƒ 3DGS å®˜æ–¹å®ç°):

```python
def prune_points(self, mask):
    """
    æ ¹æ®å¸ƒå°”æ©ç å‰ªé™¤ç‚¹

    Args:
        mask: [N] boolean tensor
              True = ä¿ç•™è¯¥ç‚¹
              False = ç§»é™¤è¯¥ç‚¹
    """
    valid_points_mask = mask

    # ä½¿ç”¨ç°æœ‰çš„ _prune_optimizer æ–¹æ³•
    optimizable_tensors = self._prune_optimizer(valid_points_mask)

    # æ›´æ–°æ‰€æœ‰å±æ€§
    self._xyz = optimizable_tensors["xyz"]
    self._features_dc = optimizable_tensors["f_dc"]
    self._features_rest = optimizable_tensors["f_rest"]
    self._opacity = optimizable_tensors["opacity"]
    self._scaling = optimizable_tensors["scaling"]
    self._rotation = optimizable_tensors["rotation"]

    # æ›´æ–°è¾…åŠ©å˜é‡
    self.xyz_gradient_accum = self.xyz_gradient_accum[valid_points_mask]
    self.denom = self.denom[valid_points_mask]
    self.max_radii2D = self.max_radii2D[valid_points_mask]
```

**éªŒè¯å‘½ä»¤:**
```bash
grep -n "def prune_points" r2_gaussian/gaussian/gaussian_model.py
```

å¦‚æœè¾“å‡ºä¸ºç©ºï¼Œéœ€è¦æ·»åŠ è¯¥æ–¹æ³•ã€‚

---

## ğŸ”§ é…ç½®å‚æ•°ä¸ä½¿ç”¨æŒ‡å—

### è®­ç»ƒå‘½ä»¤ç¤ºä¾‹

**Baseline (ä¸å¯ç”¨ Co-Pruning):**
```bash
python train.py \
    --source_path data/369/foot_50_3views.pickle \
    --model_path output/2025_11_17_foot_3views_baseline \
    --iterations 10000 \
    --test_iterations 1000 5000 10000 \
    --save_iterations 10000 \
    --eval \
    --gaussiansN 2
```

**å¯ç”¨ Co-Pruning (é»˜è®¤å‚æ•°):**
```bash
python train.py \
    --source_path data/369/foot_50_3views.pickle \
    --model_path output/2025_11_17_foot_3views_copruning \
    --iterations 10000 \
    --test_iterations 1000 5000 10000 \
    --save_iterations 10000 \
    --eval \
    --gaussiansN 2 \
    --enable_copruning \
    --copruning_interval 5 \
    --copruning_tau 5.0
```

**å¯ç”¨ Co-Pruning (æ›´ä¸¥æ ¼é˜ˆå€¼):**
```bash
python train.py \
    --source_path data/369/foot_50_3views.pickle \
    --model_path output/2025_11_17_foot_3views_copruning_tau3 \
    --iterations 10000 \
    --enable_copruning \
    --copruning_tau 3.0  # æ›´ä¸¥æ ¼çš„å‰ªæ
    ...
```

---

### å‚æ•°è¯´æ˜ä¸è°ƒä¼˜å»ºè®®

| å‚æ•° | é»˜è®¤å€¼ | èŒƒå›´ | è¯´æ˜ | ä½•æ—¶è°ƒæ•´ |
|------|-------|------|------|---------|
| `--enable_copruning` | False | - | å¯ç”¨ Co-Pruning | æ€»æ˜¯éœ€è¦æ˜ç¡®æŒ‡å®š |
| `--copruning_interval` | 5 | 3-10 | æ¯ N æ¬¡ densify æ‰§è¡Œ 1 æ¬¡ | è®ºæ–‡é»˜è®¤ï¼Œä¸€èˆ¬ä¸æ”¹ |
| `--copruning_tau` | 5.0 | 3.0-10.0 | KNN è·ç¦»é˜ˆå€¼ | æ ¹æ®åœºæ™¯å°ºåº¦è°ƒæ•´ |

**è°ƒå‚ç­–ç•¥:**

1. **é¦–æ¬¡å®éªŒ**: ä½¿ç”¨è®ºæ–‡é»˜è®¤å€¼ (interval=5, tau=5.0)
2. **å¦‚æœå‰ªé™¤è¿‡å¤š** (>30%): å¢å¤§ tau åˆ° 7.0 æˆ– 10.0
3. **å¦‚æœå‰ªé™¤è¿‡å°‘** (<5%): å‡å° tau åˆ° 3.0 æˆ– 4.0
4. **å¦‚æœè®­ç»ƒæ—¶é—´è¿‡é•¿**: å¢å¤§ interval åˆ° 7 æˆ– 10

---

## âœ… éªŒè¯æ£€æŸ¥æ¸…å•

### ä»£ç çº§åˆ«

- [ ] `r2_gaussian/utils/copruning.py` æ–‡ä»¶åˆ›å»ºå®Œæˆ
- [ ] `train.py` å¯¼å…¥ `CoPruningModule` æˆåŠŸ
- [ ] å‘½ä»¤è¡Œå‚æ•° `--enable_copruning` æ·»åŠ 
- [ ] Co-Pruning é€»è¾‘æ­£ç¡®é›†æˆåˆ° densification å¾ªç¯
- [ ] `GaussianModel.prune_points()` æ–¹æ³•å­˜åœ¨æˆ–å·²æ·»åŠ 

### åŠŸèƒ½çº§åˆ«

- [ ] è¿è¡Œ `python train.py --help` èƒ½çœ‹åˆ° Co-Pruning å‚æ•°
- [ ] å¯åŠ¨è®­ç»ƒåæ—¥å¿—è¾“å‡º "Co-Pruning enabled" æç¤º
- [ ] åœ¨ densify æ—¶æ­£ç¡®è¾“å‡º Co-Pruning æ‰§è¡Œä¿¡æ¯
- [ ] å‰ªé™¤æ¯”ä¾‹åœ¨åˆç†èŒƒå›´ (5-20%)
- [ ] ä¸å¯ç”¨ `--enable_copruning` æ—¶ baseline è¡Œä¸ºä¸å˜

### æ€§èƒ½çº§åˆ«

- [ ] PSNR â‰¥ 28.5 dB (æŒå¹³ baseline 28.547 dB)
- [ ] SSIM ä¿æŒæˆ–æå‡ (ç›®æ ‡ â‰¥ 0.90)
- [ ] è®­ç»ƒæ—¶é—´å¢åŠ  <10% (Co-Pruning å¼€é”€å¯å¿½ç•¥)
- [ ] æœ€ç»ˆ Gaussian ç‚¹æ•°åˆç† (é¢„æœŸå‡å°‘ 10-20%)

---

## âš ï¸ æ½œåœ¨é—®é¢˜ä¸è°ƒè¯•æ–¹æ¡ˆ

### é—®é¢˜ 1: å‰ªé™¤æ¯”ä¾‹è¿‡é«˜ (>30%)

**ç—‡çŠ¶**: æ¯æ¬¡ Co-Pruning ç§»é™¤ >30% ç‚¹

**åŸå› **:
- tau é˜ˆå€¼è¿‡ä¸¥æ ¼
- åœºæ™¯å½’ä¸€åŒ–å°ºåº¦é—®é¢˜

**è°ƒè¯•æ­¥éª¤**:
1. æ£€æŸ¥åœºæ™¯å½’ä¸€åŒ–èŒƒå›´ (åº”ä¸º [-1,1]Â³)
2. å¢å¤§ tau åˆ° 7.0 æˆ– 10.0
3. æ‰“å° mean_dist å’Œ max_distï¼Œåˆ†æè·ç¦»åˆ†å¸ƒ

---

### é—®é¢˜ 2: å‰ªé™¤æ¯”ä¾‹è¿‡ä½ (<2%)

**ç—‡çŠ¶**: å‡ ä¹ä¸å‰ªé™¤ä»»ä½•ç‚¹

**åŸå› **:
- tau é˜ˆå€¼è¿‡å®½æ¾
- å½“å‰åŒæ¨¡å‹ä¸€è‡´æ€§å·²ç»å¾ˆå¥½ (Fitness=1.0)

**è°ƒè¯•æ­¥éª¤**:
1. ç¡®è®¤å½“å‰ RMSE å€¼ (åº”ä¸º 0.011-0.012 mm)
2. å°è¯•å‡å° tau åˆ° 3.0 æˆ– 4.0
3. å¦‚æœä»å‰ªé™¤å¾ˆå°‘ï¼Œè¯´æ˜ Co-Pruning ç©ºé—´ç¡®å®æœ‰é™

---

### é—®é¢˜ 3: è®­ç»ƒå´©æºƒæˆ– NaN Loss

**ç—‡çŠ¶**: Co-Pruning åå‡ºç° NaN loss

**åŸå› **:
- å‰ªé™¤è¿‡å¤šå¯¼è‡´ç‚¹æ•°ä¸è¶³
- Optimizer state æœªæ­£ç¡®æ›´æ–°

**è°ƒè¯•æ­¥éª¤**:
1. æ£€æŸ¥ `prune_points()` æ–¹æ³•æ˜¯å¦æ­£ç¡®æ›´æ–° `xyz_gradient_accum` ç­‰è¾…åŠ©å˜é‡
2. å¢å¤§ tau å‡å°‘å‰ªé™¤æ¯”ä¾‹
3. æ£€æŸ¥å‰ªé™¤åç‚¹æ•°æ˜¯å¦ >1000 (è¿‡å°‘ä¼šå¯¼è‡´è®­ç»ƒå¤±è´¥)

---

### é—®é¢˜ 4: Co-Pruning æœªæ‰§è¡Œ

**ç—‡çŠ¶**: æ—¥å¿—ä¸­çœ‹ä¸åˆ° "Executing Co-Pruning" è¾“å‡º

**åŸå› **:
- `--enable_copruning` æœªæŒ‡å®š
- `--gaussiansN` ä¸ç­‰äº 2
- `densification_step_counter` æœªæ­£ç¡®é€’å¢

**è°ƒè¯•æ­¥éª¤**:
1. ç¡®è®¤å‘½ä»¤è¡Œå‚æ•°æ­£ç¡®
2. åœ¨ Co-Pruning é€»è¾‘å‰æ·»åŠ è°ƒè¯•æ‰“å°:
   ```python
   print(f"[Debug] iteration={iteration}, "
         f"densification_step_counter={densification_step_counter}, "
         f"copruning_module={copruning_module is not None}")
   ```

---

## ğŸ“Š é¢„æœŸç»“æœåˆ†ææ¡†æ¶

### å®éªŒå¯¹æ¯”è¡¨æ ¼æ¨¡æ¿

| é…ç½® | PSNR (dB) | SSIM | ç‚¹æ•° (Model 1) | ç‚¹æ•° (Model 2) | è®­ç»ƒæ—¶é—´ |
|------|----------|------|---------------|---------------|---------|
| RÂ² Baseline | 28.547 | 0.9008 | ~200k | ~200k | 15 min |
| Stage 1 Only | 28.148 | 0.8383 | ~200k | ~200k | 16 min |
| **Stage 1 + Stage 2** | **?** | **?** | **?** | **?** | **?** |

**å¡«å†™æŒ‡å—:**
1. è®­ç»ƒå®Œæˆåæå– `iter_010000/results.json`
2. ä»æ—¥å¿—æå–æœ€ç»ˆç‚¹æ•° (æœ€åä¸€æ¬¡ Co-Pruning å)
3. ä»æ—¥å¿—æå–æ€»è®­ç»ƒæ—¶é—´

---

### Co-Pruning ç»Ÿè®¡åˆ†æ

**ç›‘æ§æŒ‡æ ‡:**
```python
# åœ¨è®­ç»ƒç»“æŸåæ‰“å°ç´¯è®¡ç»Ÿè®¡
stats = copruning_module.get_stats()
print("\n===== Co-Pruning Summary =====")
print(f"Total prunings:       {stats['total_prunings']}")
print(f"Total removed Model1: {stats['total_points_removed_1']}")
print(f"Total removed Model2: {stats['total_points_removed_2']}")
print(f"Avg removal rate M1:  {stats['avg_removal_rate_1']:.2f}%")
print(f"Avg removal rate M2:  {stats['avg_removal_rate_2']:.2f}%")
```

**é¢„æœŸæ­£å¸¸èŒƒå›´:**
- Total prunings: 10-15 æ¬¡ (åŸºäº densify_until_iter=7000, interval=5)
- Avg removal rate: 5-20%
- å¦‚æœ <5%: Co-Pruning ç©ºé—´æœ‰é™
- å¦‚æœ >30%: å¯èƒ½è¿‡åº¦å‰ªæ

---

## ğŸ¯ æˆåŠŸæ ‡å‡†ä¸å†³ç­–æ ‘

### Level 1: ä»£ç å®ç°æˆåŠŸ

**æ ‡å‡†:**
- [ ] Co-Pruning æ­£ç¡®æ‰§è¡Œ (æ—¥å¿—è¾“å‡ºæ­£å¸¸)
- [ ] å‰ªé™¤æ¯”ä¾‹åœ¨åˆç†èŒƒå›´ (5-30%)
- [ ] è®­ç»ƒå®Œæˆæ— å´©æºƒ

**è¾¾æˆ â†’ è¿›å…¥ Level 2**
**æœªè¾¾æˆ â†’ è°ƒè¯•ä»£ç å®ç°**

---

### Level 2: æ€§èƒ½æŒå¹³ Baseline

**æ ‡å‡†:**
- [ ] PSNR â‰¥ 28.5 dB (vs Baseline 28.547 dB)
- [ ] SSIM â‰¥ 0.90

**è¾¾æˆ â†’ Level 2 Success â†’ è€ƒè™‘å®æ–½ Stage 3**
**æœªè¾¾æˆ â†’ è¿›å…¥å‚æ•°è°ƒä¼˜æˆ–æ›´æ¢ç­–ç•¥**

---

### Level 3: æ€§èƒ½è¶…è¶Š Baseline

**æ ‡å‡†:**
- [ ] PSNR â‰¥ 28.8 dB (è¶…è¶Š +0.25 dB)
- [ ] SSIM â‰¥ 0.905

**è¾¾æˆ â†’ Level 3 Success â†’ æ‰©å±•åˆ°å…¶ä»–æ•°æ®é›†**
**æœªè¾¾æˆä½† Level 2 è¾¾æˆ â†’ ä»ç„¶æˆåŠŸ**

---

## ğŸ“… å®æ–½æ—¶é—´è¡¨

### Day 1: æ ¸å¿ƒç®—æ³•å®ç° (2025-11-17)

**ä¸Šåˆ (3 å°æ—¶)**
- [ ] åˆ›å»º `r2_gaussian/utils/copruning.py` æ–‡ä»¶
- [ ] å®ç° `CoPruningModule` ç±»
- [ ] å®ç°è¾…åŠ©å‡½æ•° `compute_point_rmse()`
- [ ] ä»£ç  review + è¯­æ³•æ£€æŸ¥

**ä¸‹åˆ (2 å°æ—¶)**
- [ ] ç¼–å†™å•å…ƒæµ‹è¯• (æµ‹è¯• KNNã€å‰ªæé€»è¾‘)
- [ ] éªŒè¯ `GaussianModel.prune_points()` æ–¹æ³•
- [ ] å¦‚ä¸å­˜åœ¨ï¼Œæ·»åŠ è¯¥æ–¹æ³•

---

### Day 2: è®­ç»ƒé›†æˆ (2025-11-18)

**ä¸Šåˆ (3 å°æ—¶)**
- [ ] ä¿®æ”¹ `train.py` æ·»åŠ  imports å’Œå‚æ•°
- [ ] é›†æˆ Co-Pruning é€»è¾‘åˆ° densification å¾ªç¯
- [ ] æ·»åŠ æ—¥å¿—è¾“å‡ºå’Œ TensorBoard è®°å½•
- [ ] ä»£ç  review + é›†æˆæµ‹è¯•

**ä¸‹åˆ (2 å°æ—¶)**
- [ ] å¯åŠ¨é¦–æ¬¡è®­ç»ƒ (foot 3-views, 10k iterations)
- [ ] å®æ—¶ç›‘æ§æ—¥å¿—è¾“å‡º
- [ ] éªŒè¯ Co-Pruning æ‰§è¡Œé¢‘ç‡å’Œå‰ªé™¤æ¯”ä¾‹

---

### Day 3: å®éªŒéªŒè¯ (2025-11-19)

**ä¸Šåˆ (2 å°æ—¶)**
- [ ] ç­‰å¾…è®­ç»ƒå®Œæˆ (å¦‚æœ Day 2 æœªå®Œæˆ)
- [ ] æå– `iter_010000/results.json`
- [ ] å¯¹æ¯” baseline å’Œ Stage 1 ç»“æœ

**ä¸‹åˆ (3 å°æ—¶)**
- [ ] å¦‚æœæœªè¾¾æ ‡ï¼Œè°ƒæ•´å‚æ•° (tau, interval)
- [ ] å¯åŠ¨ç¬¬äºŒè½®å®éªŒéªŒè¯
- [ ] ç”Ÿæˆå®éªŒæŠ¥å‘Šæ–‡æ¡£

---

## ğŸ¤” æ‚¨çš„å†³ç­–ç‚¹

### å†³ç­–ç‚¹ 1: æ˜¯å¦ç«‹å³å®æ–½ï¼Ÿ

**å¦‚æœæ‚¨æ‰¹å‡†:**
- æˆ‘å°†ç«‹å³å¼€å§‹ Day 1 å·¥ä½œ (åˆ›å»º `copruning.py`)
- é¢„è®¡ 3 å¤©å®Œæˆå…¨éƒ¨å®æ–½å’ŒéªŒè¯

**å¦‚æœæ‚¨æš‚ç¼“:**
- å»ºè®®å…ˆå®Œæˆå…¶ä»–æ–¹æ³• (å¦‚ FSGS ä¿®å¤éªŒè¯)
- æˆ–ç­‰å¾…å•æ¨¡å‹å®éªŒç»“æœå†ï¿½ï¿½ï¿½å®š

---

### å†³ç­–ç‚¹ 2: å‚æ•°é…ç½®é€‰æ‹©

**é€‰é¡¹ A: è®ºæ–‡é»˜è®¤ (æ¨è)**
```
--copruning_interval 5
--copruning_tau 5.0
```

**é€‰é¡¹ B: ä¿å®ˆé…ç½®**
```
--copruning_interval 7
--copruning_tau 7.0
```

**é€‰é¡¹ C: æ¿€è¿›é…ç½®**
```
--copruning_interval 3
--copruning_tau 3.0
```

**æ¨èé€‰æ‹© A**ï¼Œå†æ ¹æ®ç»“æœè°ƒæ•´

---

### å†³ç­–ç‚¹ 3: éªŒè¯ç­–ç•¥

**é€‰é¡¹ A: å¿«é€ŸéªŒè¯ (1 ä¸ªå®éªŒ)**
- ä½¿ç”¨è®ºæ–‡é»˜è®¤å‚æ•°
- ä»…åœ¨ foot 3-views éªŒè¯
- æ—¶é—´: 3 å¤©

**é€‰é¡¹ B: å®Œæ•´éªŒè¯ (3 ä¸ªå®éªŒ)**
- é»˜è®¤å‚æ•° + ä¸¤ç»„æ¶ˆè (tau=3, tau=10)
- åœ¨ foot 3-views éªŒè¯
- æ—¶é—´: 5 å¤©

**æ¨èé€‰æ‹© A** (å…ˆå¿«é€ŸéªŒè¯æ˜¯å¦æœ‰æ•ˆ)

---

## ğŸ“š å‚è€ƒèµ„æ–™

**æ ¸å¿ƒè®ºæ–‡:**
- CoR-GS Section 4.1 (Co-pruning ç®—æ³•)
- Supplementary Material Table I (è¶…å‚æ•°æ•æ„Ÿæ€§)
- Table 6 (æ¶ˆèç ”ç©¶)

**ä»£ç å®ç°å‚è€ƒ:**
- PyTorch3D knn_points API: https://pytorch3d.readthedocs.io/en/latest/modules/ops.html#pytorch3d.ops.knn_points
- 3DGS Official Implementation: https://github.com/graphdeco-inria/gaussian-splatting

**ç›¸å…³æ–‡æ¡£:**
- `cc-agent/3dgs_expert/innovation_analysis_corgs_stage2.md` (æŠ€æœ¯åˆ†æ)
- `cc-agent/3dgs_expert/corgs_innovation_analysis.md` (Stage 1 åˆ†æ)

---

**æ–‡æ¡£ç”Ÿæˆæ—¶é—´**: 2025-11-17 15:45
**ç‰ˆæœ¬**: v1.0
**å­—æ•°**: 2487 å­—
**è´Ÿè´£ä¸“å®¶**: @3dgs-research-expert
**å®¡æ ¸çŠ¶æ€**: å¾…ç”¨æˆ·æ‰¹å‡†

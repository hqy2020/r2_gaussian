# SSS Bug ä¿®å¤æ–¹æ¡ˆï¼ˆåŸºäºå®˜æ–¹ä»£ç ç ”ç©¶ï¼‰

**ç ”ç©¶æ—¥æœŸï¼š** 2025-11-18
**å®˜æ–¹ä»“åº“ï¼š** https://github.com/realcrane/3D-student-splatting-and-scooping
**ç›®æ ‡ï¼š** ä¿®å¤ç”¨æˆ· SSS å®ç°ä¸­çš„ 5 ä¸ªè‡´å‘½ bugï¼Œæ¢å¤æ€§èƒ½ä» -8.39 dB å›åˆ° Baseline æ°´å¹³æˆ–æ›´å¥½

---

## ç¬¬ä¸€éƒ¨åˆ†ï¼šå®˜æ–¹ä»£ç ç ”ç©¶ç»“æœ

### 1. è®­ç»ƒå‚æ•°è®¾ç½®

ä»å®˜æ–¹ `arguments/__init__.py` å’Œé…ç½®æ–‡ä»¶ `configs/bicycle.json` æå–çš„å…³é”®å‚æ•°ï¼š

| å‚æ•°å | é»˜è®¤å€¼ | è¯´æ˜ |
|--------|--------|------|
| `nu_degree` | 10 (é»˜è®¤) / 100 (bicycle) | Student-t åˆ†å¸ƒè‡ªç”±åº¦åˆå§‹å€¼ |
| `opacity_threshold` | 0.005 | Opacity è¿‡æ»¤é˜ˆå€¼ï¼ˆç”¨äºç»„ä»¶å›æ”¶ï¼‰ |
| `opacity_lr` | 0.005 | Opacity å­¦ä¹ ç‡ |
| `opacity_reset_interval` | 3000 | Opacity é‡ç½®é—´éš” |
| `opacity_reg` | 0.01 | **Balance Loss æƒé‡** |
| `C_burnin` | 5e8 (bicycle) / 5e5 (é»˜è®¤) | SGHMC burn-in é˜¶æ®µå™ªå£°ç³»æ•° |
| `C` | 1.2e2 (bicycle) / 1e2 (é»˜è®¤) | SGHMC ä¸»è®­ç»ƒé˜¶æ®µå™ªå£°ç³»æ•° |
| `burnin_iterations` | 15000 (bicycle) / 7000 (é»˜è®¤) | Burn-in è¿­ä»£æ¬¡æ•° |
| `cap_max` | 3000000 | æœ€å¤§ç»„ä»¶æ•° |

**å…³é”®å‘ç°ï¼š**
- âœ… å®˜æ–¹**æ²¡æœ‰** `use_student_t` å‚æ•°ï¼ŒStudent-t æ˜¯**é»˜è®¤å¯ç”¨**çš„
- âœ… Balance Loss æ˜¯ç®€å•çš„ **`opacity_reg * torch.abs(opacity).mean()`**ï¼ˆL1 æ­£åˆ™ï¼‰
- âœ… ä¸å­˜åœ¨"æ¸è¿›å¼ Scooping é™åˆ¶"æˆ–"æ­£è´Ÿå€¼æ¯”ä¾‹æ§åˆ¶"

### 2. Opacity æ¿€æ´»å‡½æ•°

ä»å®˜æ–¹ `scene/nt_model.py` çš„å®ç°ï¼š

```python
# å®˜æ–¹å®ç°
self.opacity_activation = torch.tanh
self.inverse_opacity_activation = inverse_tanh

# åˆå§‹åŒ–
opacities = self.inverse_opacity_activation(0.5 * torch.ones(...))

# Clamping (åœ¨ get_opacity ä¸­)
opacity = torch.clamp(opacity, -1 + 1e-5, 1 - 1e-5)
```

**å…³é”®ç‰¹æ€§ï¼š**
- âœ… ä½¿ç”¨ **`tanh`** æ¿€æ´»å‡½æ•°ï¼Œå€¼åŸŸä¸¥æ ¼ **[-1, 1]**
- âœ… åˆå§‹åŒ–ä¸º **0.5**ï¼ˆç»è¿‡ `inverse_tanh` æ˜ å°„åˆ°å‚æ•°ç©ºé—´ï¼‰
- âœ… Clamp èŒƒå›´ï¼š**[-1 + Îµ, 1 - Îµ]**ï¼ˆé¿å…æ•°å€¼ä¸ç¨³å®šï¼‰
- âš ï¸ **ä¸æ˜¯ç”¨æˆ·å®ç°çš„ `[-0.2, 1.0]` èŒƒå›´ï¼**

### 3. ç»„ä»¶å›æ”¶æœºåˆ¶ï¼ˆComponent Recyclingï¼‰

ä»å®˜æ–¹ `scene/nt_model.py` çš„ `recycle_components` æ–¹æ³•ï¼š

```python
def recycle_components(self):
    # 1. è¯†åˆ« dead components
    opacity = self.get_opacity
    alive_mask = opacity > self.opacity_threshold  # 0.005
    dead_mask = ~alive_mask

    # 2. é™åˆ¶å›æ”¶æ•°é‡ï¼ˆ5% capï¼‰
    max_recycle = int(0.05 * opacity.shape[0])
    dead_indices = torch.where(dead_mask)[0]
    if len(dead_indices) > max_recycle:
        dead_indices = dead_indices[:max_recycle]

    # 3. ä»å­˜æ´»ç»„ä»¶ä¸­é‡æ–°é‡‡æ ·ï¼ˆåŸºäº opacityï¼‰
    alive_indices = torch.where(alive_mask)[0]
    sample_weights = opacity[alive_mask].squeeze()
    sample_indices = torch.multinomial(sample_weights, len(dead_indices), replacement=True)
    source_indices = alive_indices[sample_indices]

    # 4. é‡æ–°åˆå§‹åŒ– dead components
    self._xyz[dead_indices] = self._xyz[source_indices] + torch.randn_like(...) * 0.01
    self._opacity[dead_indices] = self.inverse_opacity_activation(torch.ones_like(...) * 0.5)
    self._nu[dead_indices] = self._nu[source_indices].clone()
    # ... å¤åˆ¶å…¶ä»–å‚æ•° ...

    # 5. é‡ç½®ä¼˜åŒ–å™¨åŠ¨é‡
    self.optimizer.reset_state(dead_indices)
```

**å…³é”®é€»è¾‘ï¼š**
- âœ… **æ¯æ¬¡æœ€å¤šå›æ”¶ 5% æ€»ç»„ä»¶æ•°**
- âœ… ä½ opacity é˜ˆå€¼ï¼š**0.005**
- âœ… é›¶ opacity é‡æ–°åˆå§‹åŒ–åˆ° **0.5**
- âœ… ä»é«˜ opacity ç»„ä»¶é‡æ–°é‡‡æ ·
- âš ï¸ **å®Œå…¨æ›¿ä»£ä¼ ç»Ÿ densification**ï¼Œä¸æ˜¯å¹¶å­˜

### 4. æ¸²æŸ“é€»è¾‘

ä»å®˜æ–¹ `t_renderer/__init__.py`ï¼š

```python
def render(viewpoint_camera, pc, pipe, bg_color, ...):
    # è·å–å‚æ•°
    opacity = pc.get_opacity  # å·²ç»è¿‡ tanh æ¿€æ´»
    nu_degree = pc.get_nu_degree
    negative_value = pc.get_negative

    # ä¼ é€’ç»™ CUDA å…‰æ …åŒ–å™¨
    rendered_image, radii = rasterizer(
        means3D=xyz,
        opacity=opacity,  # [-1, 1] èŒƒå›´
        nu_degree=nu_degree,
        negative_value=negative_value,
        ...
    )
```

**å…³é”®å‘ç°ï¼š**
- âœ… Opacity ç›´æ¥ä¼ é€’ç»™å…‰æ …åŒ–å™¨ï¼Œ**ä¸åœ¨æ¸²æŸ“å‡½æ•°ä¸­ clamp**
- âœ… **Clamp åœ¨æ¨¡å‹çš„ `get_opacity` ä¸­å®Œæˆ**
- âœ… å¼•å…¥ `negative_value` å‚æ•°æ”¯æŒè´Ÿå¯†åº¦

### 5. Balance Lossï¼ˆå®˜æ–¹å®ç°ï¼‰

ä»å®˜æ–¹ `train.py` å’Œ `arguments/__init__.py`ï¼š

```python
# å®˜æ–¹ Balance Lossï¼ˆL1 æ­£åˆ™ï¼‰
opacity = primitives.get_opacity
balance_loss = args.opacity_reg * torch.abs(opacity).mean()

loss = L1_loss + ssim_loss + balance_loss
```

**å…³é”®å…¬å¼ï¼š**
- âœ… **Balance Loss = `Î» * Î£|o_i|_1`**ï¼ˆè®ºæ–‡å…¬å¼ï¼‰
- âœ… é»˜è®¤æƒé‡ï¼š**Î» = 0.01**
- âŒ **ä¸æ˜¯ç”¨æˆ·å®ç°çš„å¤æ‚"æ­£è´Ÿå€¼æ¯”ä¾‹æ§åˆ¶"**

---

## ç¬¬äºŒéƒ¨åˆ†ï¼šBug ä¿®å¤è¯¦ç»†æ–¹æ¡ˆ

### Bug 1: å¯ç”¨ SSS

**é—®é¢˜æè¿°ï¼š**
- æ–‡ä»¶ï¼š`train.py`
- è¡Œå·ï¼š142
- å½“å‰ä»£ç ï¼š`use_student_t = False  # å¼ºåˆ¶ç¦ç”¨ SSS`

**ä¿®å¤æ–¹æ¡ˆï¼š**

```python
# ä¿®æ”¹å‰
use_student_t = False  # å¼ºåˆ¶ç¦ç”¨ SSS

# ä¿®æ”¹å
use_student_t = args.enable_sss  # å…è®¸é€šè¿‡å‘½ä»¤è¡Œå‚æ•°å¯ç”¨ SSS
```

**å½±å“ï¼š**
- å¯ç”¨åå°†ä½¿ç”¨ Student-t åˆ†å¸ƒå’Œ SGHMC ä¼˜åŒ–å™¨
- éœ€ç¡®ä¿ `--enable_sss` å‘½ä»¤è¡Œå‚æ•°æ­£ç¡®ä¼ é€’

---

### Bug 2: Opacity æ¿€æ´»å‡½æ•°é”™è¯¯

**é—®é¢˜æè¿°ï¼š**
- æ–‡ä»¶ï¼š`r2_gaussian/gaussian/gaussian_model.py`
- è¡Œå·ï¼š72-78
- å½“å‰ä»£ç ï¼š`opacity_activation = lambda x: torch.sigmoid(x) * 1.2 - 0.2  # [-0.2, 1.0]`
- **é”™è¯¯ï¼š** å€¼åŸŸ `[-0.2, 1.0]` ä¸è®ºæ–‡çš„ `[-1, 1]` ä¸ç¬¦

**ä¿®å¤æ–¹æ¡ˆï¼š**

```python
# ä¿®æ”¹å‰ï¼ˆè¡Œ 72-78ï¼‰
self.opacity_activation = lambda x: torch.sigmoid(x) * 1.2 - 0.2  # [-0.2, 1.0]
self.opacity_inverse_activation = lambda x: inverse_sigmoid(
    (torch.clamp(x, -0.19, 0.99) + 0.2) / 1.2
)

# ä¿®æ”¹å
self.opacity_activation = torch.tanh  # [-1, 1] èŒƒå›´ï¼ˆå®˜æ–¹å®ç°ï¼‰
self.opacity_inverse_activation = lambda x: 0.5 * torch.log(
    (1 + torch.clamp(x, -0.99, 0.99)) / (1 - torch.clamp(x, -0.99, 0.99))
)  # inverse_tanh with numerical stability
```

**åŒæ—¶ä¿®æ”¹åˆå§‹åŒ–é€»è¾‘ï¼ˆè¡Œ 291-295ï¼‰ï¼š**

```python
# ä¿®æ”¹å‰
opacity_vals = torch.sigmoid(fused_density.clone()) * 0.9  # [0, 0.9]
opacity_init = self.opacity_inverse_activation(opacity_vals)

# ä¿®æ”¹å
opacity_vals = torch.ones_like(fused_density) * 0.5  # åˆå§‹åŒ–ä¸º 0.5ï¼ˆå®˜æ–¹ç­–ç•¥ï¼‰
opacity_init = self.opacity_inverse_activation(opacity_vals)
```

**æ·»åŠ  `get_opacity` ä¸­çš„ Clampï¼ˆå¦‚æœè¿˜æ²¡æœ‰ï¼‰ï¼š**

```python
@property
def get_opacity(self):
    if self.use_student_t:
        opacity = self.opacity_activation(self._opacity)
        # å®˜æ–¹ clamp é€»è¾‘
        return torch.clamp(opacity, -1.0 + 1e-5, 1.0 - 1e-5)
    else:
        return self.opacity_activation(self._opacity)
```

---

### Bug 3: ç§»é™¤æ¸è¿›å¼ Scooping é™åˆ¶

**é—®é¢˜æè¿°ï¼š**
- æ–‡ä»¶ï¼š`train.py`
- è¡Œå·ï¼š792-843
- **è‡ªåˆ›é€»è¾‘ï¼š** å¤æ‚çš„æ­£è´Ÿå€¼æ¯”ä¾‹æ§åˆ¶ï¼ˆ`balance_loss`ï¼‰ï¼Œè®ºæ–‡ä¸­ä¸å­˜åœ¨

**ä¿®å¤æ–¹æ¡ˆï¼š**

å°†è¡Œ 792-843 çš„æ•´ä¸ªè‡ªåˆ› Balance Loss é€»è¾‘æ›¿æ¢ä¸ºå®˜æ–¹çš„ç®€å• L1 æ­£åˆ™ï¼š

```python
# å®Œå…¨åˆ é™¤è¡Œ 792-843 çš„ä»£ç 
# åˆ é™¤ï¼š
#   - negative_penalty
#   - positive_encouragement
#   - balance_loss å¤æ‚å…¬å¼
#   - nu_diversity_loss
#   - æ‰€æœ‰ç›¸å…³çš„ debug logging

# æ›¿æ¢ä¸ºå®˜æ–¹å®ç°ï¼ˆæ’å…¥åˆ°è¡Œ 792 ä½ç½®ï¼‰
if hasattr(GsDict[f"gs{i}"], 'use_student_t') and GsDict[f"gs{i}"].use_student_t:
    opacity = GsDict[f"gs{i}"].get_opacity
    # å®˜æ–¹ Balance Loss: L1 æ­£åˆ™åŒ–
    opacity_reg_weight = 0.01  # å®˜æ–¹é»˜è®¤æƒé‡
    balance_loss = opacity_reg_weight * torch.abs(opacity).mean()
    LossDict[f"loss_gs{i}"] += balance_loss

    # ç®€åŒ–çš„æ—¥å¿—ï¼ˆæ¯ 2000 æ¬¡è¿­ä»£ï¼‰
    if iteration % 2000 == 0:
        pos_ratio = (opacity > 0).float().mean()
        neg_ratio = (opacity < 0).float().mean()
        print(f"ğŸ¯ [SSS-Official] Iter {iteration}: "
              f"Opacity range [{opacity.min():.3f}, {opacity.max():.3f}], "
              f"Balance: {pos_ratio*100:.1f}% pos / {neg_ratio*100:.1f}% neg, "
              f"Balance Loss: {balance_loss.item():.6f}")
```

---

### Bug 4: Balance Loss å…¬å¼é”™è¯¯

**é—®é¢˜ï¼š** å·²åœ¨ Bug 3 ä¸­ä¿®å¤ã€‚

**æ€»ç»“ï¼š**
- âŒ ç”¨æˆ·è‡ªåˆ›ï¼š`negative_penalty + positive_encouragement`
- âœ… å®˜æ–¹å®ç°ï¼š**`0.01 * torch.abs(opacity).mean()`**

---

### Bug 5: ç»„ä»¶å›æ”¶æœºåˆ¶ç¼ºå¤±

**é—®é¢˜æè¿°ï¼š**
- æ–‡ä»¶ï¼š`train.py` å’Œ `gaussian_model.py`
- å½“å‰ä»£ç ï¼šä½¿ç”¨ä¼ ç»Ÿ `densify_and_prune`
- **ç¼ºå¤±ï¼š** è®ºæ–‡æ ¸å¿ƒçš„ç»„ä»¶å›æ”¶ï¼ˆComponent Recyclingï¼‰æœºåˆ¶

**ä¿®å¤æ–¹æ¡ˆï¼ˆåˆ† 2 æ­¥ï¼‰ï¼š**

#### æ­¥éª¤ 1ï¼šåœ¨ `gaussian_model.py` ä¸­æ·»åŠ  `recycle_components` æ–¹æ³•

åœ¨ `GaussianModel` ç±»ä¸­æ·»åŠ ä»¥ä¸‹æ–¹æ³•ï¼ˆå»ºè®®æ’å…¥åˆ° `densify_and_prune` æ–¹æ³•ä¹‹åï¼‰ï¼š

```python
def recycle_components(self, opacity_threshold=0.005, max_recycle_ratio=0.05):
    """
    ç»„ä»¶å›æ”¶æœºåˆ¶ï¼ˆå®˜æ–¹å®ç°ï¼‰

    å‚æ•°ï¼š
        opacity_threshold: ä½ opacity é˜ˆå€¼ï¼Œä½äºæ­¤å€¼è§†ä¸º dead component
        max_recycle_ratio: æ¯æ¬¡æœ€å¤šå›æ”¶çš„ç»„ä»¶æ¯”ä¾‹ï¼ˆé»˜è®¤ 5%ï¼‰
    """
    if not self.use_student_t:
        return  # ä»… SSS å¯ç”¨

    with torch.no_grad():
        # 1. è¯†åˆ« dead components
        opacity = self.get_opacity
        alive_mask = torch.abs(opacity) > opacity_threshold  # ä½¿ç”¨ç»å¯¹å€¼
        dead_mask = ~alive_mask

        num_dead = dead_mask.sum().item()
        if num_dead == 0:
            return

        # 2. é™åˆ¶å›æ”¶æ•°é‡ï¼ˆ5% capï¼‰
        max_recycle = int(max_recycle_ratio * opacity.shape[0])
        dead_indices = torch.where(dead_mask)[0]
        if len(dead_indices) > max_recycle:
            # éšæœºé€‰æ‹©è¦å›æ”¶çš„ç»„ä»¶
            perm = torch.randperm(len(dead_indices), device=dead_indices.device)
            dead_indices = dead_indices[perm[:max_recycle]]

        num_to_recycle = len(dead_indices)

        # 3. ä»å­˜æ´»ç»„ä»¶ä¸­é‡æ–°é‡‡æ ·ï¼ˆåŸºäº opacity æƒé‡ï¼‰
        alive_indices = torch.where(alive_mask)[0]
        if len(alive_indices) == 0:
            print("âš ï¸ [SSS-Recycle] No alive components, skipping recycling")
            return

        # ä½¿ç”¨ opacity ç»å¯¹å€¼ä½œä¸ºé‡‡æ ·æƒé‡
        sample_weights = torch.abs(opacity[alive_mask].squeeze())
        sample_weights = sample_weights / sample_weights.sum()  # å½’ä¸€åŒ–

        # é‡æ–°é‡‡æ ·æºç»„ä»¶
        sample_indices = torch.multinomial(sample_weights, num_to_recycle, replacement=True)
        source_indices = alive_indices[sample_indices]

        # 4. é‡æ–°åˆå§‹åŒ– dead components
        # Position: æ·»åŠ å°å™ªå£°
        self._xyz[dead_indices] = self._xyz[source_indices].clone() + torch.randn_like(self._xyz[dead_indices]) * 0.01

        # Opacity: é‡ç½®ä¸º 0.5ï¼ˆå®˜æ–¹ç­–ç•¥ï¼‰
        opacity_init_val = 0.5 * torch.ones(num_to_recycle, 1, device="cuda")
        self._opacity[dead_indices] = self.opacity_inverse_activation(opacity_init_val)

        # Nu: ç»§æ‰¿æºç»„ä»¶
        self._nu[dead_indices] = self._nu[source_indices].clone()

        # Scaling: ç»§æ‰¿æºç»„ä»¶
        self._scaling[dead_indices] = self._scaling[source_indices].clone()

        # Rotation: ç»§æ‰¿æºç»„ä»¶
        self._rotation[dead_indices] = self._rotation[source_indices].clone()

        # Density: ç»§æ‰¿æºç»„ä»¶
        self._density[dead_indices] = self._density[source_indices].clone()

        # 5. é‡ç½®ä¼˜åŒ–å™¨çŠ¶æ€ï¼ˆé‡è¦ï¼ï¼‰
        # æ¸…é™¤å›æ”¶ç»„ä»¶çš„æ¢¯åº¦å’ŒåŠ¨é‡
        for param_group in self.optimizer.param_groups:
            for param_name, param in [
                ('xyz', self._xyz),
                ('opacity', self._opacity),
                ('nu', self._nu),
                ('scaling', self._scaling),
                ('rotation', self._rotation),
                ('density', self._density)
            ]:
                if param_group['name'] == param_name:
                    state = self.optimizer.state[param]
                    if len(state) > 0:
                        # æ¸…é™¤åŠ¨é‡
                        if 'exp_avg' in state:
                            state['exp_avg'][dead_indices] = 0
                        if 'exp_avg_sq' in state:
                            state['exp_avg_sq'][dead_indices] = 0

        print(f"ğŸ”„ [SSS-Recycle] Recycled {num_to_recycle}/{num_dead} dead components "
              f"(threshold={opacity_threshold}, cap={max_recycle})")
```

#### æ­¥éª¤ 2ï¼šåœ¨ `train.py` ä¸­å¯ç”¨ç»„ä»¶å›æ”¶ï¼ˆæ›¿æ¢ densificationï¼‰

ä¿®æ”¹è®­ç»ƒå¾ªç¯ä¸­çš„å¯†åŒ–é€»è¾‘ï¼ˆè¡Œ 865-980 åŒºåŸŸï¼‰ï¼š

```python
# åœ¨è¡Œ 865 é™„è¿‘ï¼Œdensification å¾ªç¯å¼€å§‹å‰æ·»åŠ ï¼š

# SSS: Component Recyclingï¼ˆæ›¿ä»£ä¼ ç»Ÿ densificationï¼‰
if iteration < opt.densify_until_iter:
    if iteration > opt.densify_from_iter and iteration % opt.densification_interval == 0:
        for i in range(gaussiansN):
            if hasattr(GsDict[f"gs{i}"], 'use_student_t') and GsDict[f"gs{i}"].use_student_t:
                # ğŸ¯ [SSS-Official] ä½¿ç”¨ç»„ä»¶å›æ”¶æœºåˆ¶ï¼ˆä¸æ˜¯ä¼ ç»Ÿ densificationï¼‰
                print(f"ğŸ”„ [SSS-Recycle] Iter {iteration}: Applying component recycling for GS{i}")
                GsDict[f"gs{i}"].recycle_components(
                    opacity_threshold=0.005,  # å®˜æ–¹é˜ˆå€¼
                    max_recycle_ratio=0.05    # æ¯æ¬¡æœ€å¤š 5%
                )
            else:
                # æ ‡å‡† Gaussian æ¨¡å‹ï¼šä½¿ç”¨ä¼ ç»Ÿ densification
                # ... ä¿ç•™åŸæœ‰ densify_and_prune é€»è¾‘ ...
```

**å®Œæ•´ä¿®æ”¹å»ºè®®ï¼š**

å°†è¡Œ 910-979ï¼ˆæ ‡å‡† densification é€»è¾‘ï¼‰ä¿®æ”¹ä¸ºï¼š

```python
# æ ‡å‡†å¯†åŒ–å’Œå‰ªææµç¨‹
for i in range(gaussiansN):
    # SSS: ä½¿ç”¨ç»„ä»¶å›æ”¶æœºåˆ¶
    if hasattr(GsDict[f"gs{i}"], 'use_student_t') and GsDict[f"gs{i}"].use_student_t:
        print(f"ğŸ”„ [SSS-Official] Iter {iteration}: GS{i} using component recycling (not densification)")
        GsDict[f"gs{i}"].recycle_components(
            opacity_threshold=0.005,
            max_recycle_ratio=0.05
        )
    else:
        # é SSS æ¨¡å‹ï¼šä¼ ç»Ÿ densification
        if hasattr(GsDict[f"gs{i}"], 'enhanced_densify_and_prune'):
            print(f"âœ… [Densify] Iter {iteration}: GS{i} ä½¿ç”¨ FSGS enhanced_densify_and_prune")
            GsDict[f"gs{i}"].enhanced_densify_and_prune(
                opt.densify_grad_threshold,
                opt.density_min_threshold,
                opt.max_screen_size,
                max_scale,
                opt.max_num_gaussians,
                densify_scale_threshold,
                bbox,
                enable_proximity_densify=enable_fsgs_proximity,
            )
        else:
            # å›é€€åˆ°æ ‡å‡†å¯†åŒ–
            print(f"âš ï¸ [Densify] Iter {iteration}: GS{i} å›é€€åˆ°æ ‡å‡† densify_and_prune (æ— FSGS)")
            GsDict[f"gs{i}"].densify_and_prune(
                opt.densify_grad_threshold,
                opt.density_min_threshold,
                opt.max_screen_size,
                max_scale,
                opt.max_num_gaussians,
                densify_scale_threshold,
                bbox,
            )
```

---

## ç¬¬ä¸‰éƒ¨åˆ†ï¼šä¿®å¤æ‰§è¡Œè®¡åˆ’

### é˜¶æ®µ 1ï¼šç®€å•ä¿®å¤ï¼ˆBug 1-3ï¼‰

**ä¼˜å…ˆçº§ï¼šğŸ”¥ é«˜ï¼ˆç«‹å³æ‰§è¡Œï¼‰**

#### ä¿®å¤ 1.1ï¼šå¯ç”¨ SSSï¼ˆBug 1ï¼‰

```python
# æ–‡ä»¶: train.py
# è¡Œå·: 142
# æ“ä½œ: Edit

# æ—§ä»£ç :
use_student_t = False  # å¼ºåˆ¶ç¦ç”¨ SSS

# æ–°ä»£ç :
use_student_t = args.enable_sss  # å…è®¸é€šè¿‡å‘½ä»¤è¡Œå‚æ•°å¯ç”¨
```

#### ä¿®å¤ 1.2ï¼šOpacity æ¿€æ´»å‡½æ•°ï¼ˆBug 2ï¼‰

```python
# æ–‡ä»¶: r2_gaussian/gaussian/gaussian_model.py
# è¡Œå·: 72-78
# æ“ä½œ: Edit

# æ—§ä»£ç :
self.opacity_activation = lambda x: torch.sigmoid(x) * 1.2 - 0.2  # [-0.2, 1.0]
self.opacity_inverse_activation = lambda x: inverse_sigmoid(
    (torch.clamp(x, -0.19, 0.99) + 0.2) / 1.2
)

# æ–°ä»£ç :
# ğŸ¯ [SSS-Official] ä½¿ç”¨ tanh æ¿€æ´»å‡½æ•° [-1, 1]ï¼ˆå®˜æ–¹å®ç°ï¼‰
self.opacity_activation = torch.tanh
self.opacity_inverse_activation = lambda x: 0.5 * torch.log(
    (1 + torch.clamp(x, -0.99, 0.99)) / (1 - torch.clamp(x, -0.99, 0.99))
)  # inverse_tanh
```

```python
# æ–‡ä»¶: r2_gaussian/gaussian/gaussian_model.py
# è¡Œå·: 291-295
# æ“ä½œ: Edit

# æ—§ä»£ç :
opacity_vals = torch.sigmoid(fused_density.clone()) * 0.9  # [0, 0.9]
opacity_init = self.opacity_inverse_activation(opacity_vals)
self._opacity = nn.Parameter(opacity_init.requires_grad_(True))

# æ–°ä»£ç :
# ğŸ¯ [SSS-Official] åˆå§‹åŒ–ä¸º 0.5ï¼ˆå®˜æ–¹ç­–ç•¥ï¼‰
opacity_vals = torch.ones_like(fused_density) * 0.5
opacity_init = self.opacity_inverse_activation(opacity_vals)
self._opacity = nn.Parameter(opacity_init.requires_grad_(True))
```

```python
# æ–‡ä»¶: r2_gaussian/gaussian/gaussian_model.py
# è¡Œå·: 201-206ï¼ˆget_opacity å±æ€§ï¼‰
# æ“ä½œ: ä¿®æ”¹æˆ–æ·»åŠ  clamp

# ç¡®ä¿ get_opacity ä¸­æœ‰å®˜æ–¹çš„ clamp é€»è¾‘
@property
def get_opacity(self):
    if self.use_student_t:
        opacity = self.opacity_activation(self._opacity)
        # ğŸ¯ [SSS-Official] Clamp åˆ° [-1+Îµ, 1-Îµ]
        return torch.clamp(opacity, -1.0 + 1e-5, 1.0 - 1e-5)
    else:
        return self.density_activation(self._density)
```

#### ä¿®å¤ 1.3ï¼šç§»é™¤è‡ªåˆ› Balance Lossï¼ˆBug 3ï¼‰

```python
# æ–‡ä»¶: train.py
# è¡Œå·: 792-843
# æ“ä½œ: åˆ é™¤æ—§ä»£ç ï¼Œæ›¿æ¢ä¸ºå®˜æ–¹å®ç°

# åˆ é™¤æ‰€æœ‰è¡Œ 792-843 çš„ä»£ç ï¼ˆåŒ…æ‹¬æ³¨é‡Šï¼‰

# åœ¨è¡Œ 792 ä½ç½®æ’å…¥å®˜æ–¹ Balance Loss:
# ğŸ¯ [SSS-Official] Balance Loss: L1 æ­£åˆ™åŒ–
if hasattr(GsDict[f"gs{i}"], 'use_student_t') and GsDict[f"gs{i}"].use_student_t:
    opacity = GsDict[f"gs{i}"].get_opacity
    opacity_reg_weight = 0.01  # å®˜æ–¹é»˜è®¤æƒé‡
    balance_loss = opacity_reg_weight * torch.abs(opacity).mean()
    LossDict[f"loss_gs{i}"] += balance_loss

    # ç®€åŒ–æ—¥å¿—ï¼ˆæ¯ 2000 æ¬¡è¿­ä»£ï¼‰
    if iteration % 2000 == 0:
        pos_ratio = (opacity > 0).float().mean()
        neg_ratio = (opacity < 0).float().mean()
        nu = GsDict[f"gs{i}"].get_nu
        print(f"ğŸ¯ [SSS-Official] Iter {iteration}: "
              f"Opacity [{opacity.min():.3f}, {opacity.max():.3f}], "
              f"Pos/Neg: {pos_ratio*100:.1f}%/{neg_ratio*100:.1f}%, "
              f"Nu: [{nu.min():.2f}, {nu.max():.2f}], "
              f"Balance Loss: {balance_loss.item():.6f}")
```

### é˜¶æ®µ 2ï¼šç»„ä»¶å›æ”¶å®ç°ï¼ˆBug 5ï¼‰

**ä¼˜å…ˆçº§ï¼šğŸ”¥ å…³é”®ï¼ˆæ ¸å¿ƒåŠŸèƒ½ï¼‰**

#### ä¿®å¤ 2.1ï¼šæ·»åŠ  `recycle_components` æ–¹æ³•

åœ¨ `r2_gaussian/gaussian/gaussian_model.py` ä¸­æ·»åŠ å®Œæ•´æ–¹æ³•ï¼ˆè§ä¸Šæ–‡"æ­¥éª¤ 1"çš„å®Œæ•´ä»£ç ï¼‰

#### ä¿®å¤ 2.2ï¼šåœ¨è®­ç»ƒå¾ªç¯ä¸­å¯ç”¨

ä¿®æ”¹ `train.py` è¡Œ 910-979 çš„ densification é€»è¾‘ï¼ˆè§ä¸Šæ–‡"æ­¥éª¤ 2"çš„å®Œæ•´ä»£ç ï¼‰

---

## ç¬¬å››éƒ¨åˆ†ï¼šéªŒè¯ä¸æµ‹è¯•

### ä¿®å¤åçš„è®­ç»ƒå‘½ä»¤

```bash
# å¯ç”¨ SSS çš„å®Œæ•´è®­ç»ƒå‘½ä»¤
python train.py \
    --source_path data/foot/foot_3views \
    --model_path output/2025_11_18_foot_3views_sss_fixed \
    --config configs/foot_3views.yaml \
    --enable_sss \
    --iterations 20000 \
    --test_iterations 5000 10000 20000 \
    --save_iterations 5000 10000 20000 \
    --gaussiansN 1 \
    --coreg False
```

### é¢„æœŸæ•ˆæœ

| æŒ‡æ ‡ | Baseline | ç”¨æˆ· Bug ç‰ˆæœ¬ | ä¿®å¤åé¢„æœŸ |
|------|----------|---------------|------------|
| **PSNR (3D)** | ~18.99 dB | 10.60 dB | **â‰¥ 18.99 dB** |
| **SSIM (3D)** | ~0.88 | 0.83 | **â‰¥ 0.88** |
| **è®­ç»ƒç¨³å®šæ€§** | ç¨³å®š | æ˜“å´©æºƒ | ç¨³å®š |
| **Opacity å¹³è¡¡** | - | å…¨è´Ÿå€¼ | **~70% æ­£å€¼ / 30% è´Ÿå€¼** |

### ç›‘æ§æŒ‡æ ‡

åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­è§‚å¯Ÿä»¥ä¸‹å…³é”®æŒ‡æ ‡ï¼ˆTensorBoardï¼‰ï¼š

1. **Opacity åˆ†å¸ƒ**
   - èŒƒå›´åº”åœ¨ **[-1, 1]**
   - æ­£å€¼æ¯”ä¾‹åº”åœ¨ **60%-80%**
   - æç«¯å€¼ï¼ˆ< -0.9 æˆ– > 0.9ï¼‰åº”å°‘äº **5%**

2. **Balance Loss**
   - åº”åœ¨ **0.001 - 0.01** ä¹‹é—´
   - è¶‹åŠ¿åº”å¹³ç¨³ä¸‹é™

3. **ç»„ä»¶å›æ”¶**
   - æ¯æ¬¡å›æ”¶ **â‰¤ 5% æ€»ç»„ä»¶æ•°**
   - å›æ”¶é¢‘ç‡ï¼šæ¯ **100-500 iterations**

4. **Nu (è‡ªç”±åº¦)**
   - èŒƒå›´åº”åœ¨ **[2, 8]**
   - å¹³å‡å€¼çº¦ **4-6**

### è¯Šæ–­å‘½ä»¤

å¦‚æœä¿®å¤åä»æœ‰é—®é¢˜ï¼Œè¿è¡Œä»¥ä¸‹å‘½ä»¤è¯Šæ–­ï¼š

```bash
# æ£€æŸ¥åˆå§‹åŒ–
python train.py --source_path data/foot/foot_3views \
    --model_path output/test_init \
    --enable_sss \
    --iterations 1 \
    --test_iterations 1

# æŸ¥çœ‹æ—¥å¿—è¾“å‡ºä¸­çš„åˆå§‹åŒ–ä¿¡æ¯ï¼š
# âœ… "SSS-v6-FIX] Initialize N Student's t distributions"
# âœ… "Initialized nu: [...], opacity: [...], positive: ...%"

# æ£€æŸ¥ç»„ä»¶å›æ”¶
grep "SSS-Recycle" output/test_sss/log.txt
```

---

## ç¬¬äº”éƒ¨åˆ†ï¼šé£é™©ä¸æ³¨æ„äº‹é¡¹

### å·²çŸ¥é£é™©

1. **CUDA å…‰æ …åŒ–å™¨å…¼å®¹æ€§**
   - ç”¨æˆ·å¯èƒ½æ²¡æœ‰æ”¯æŒ Student-t çš„ CUDA å…‰æ …åŒ–å™¨
   - **è§£å†³æ–¹æ¡ˆï¼š** æ£€æŸ¥ `submodules/diff-t-rasterization` æ˜¯å¦å­˜åœ¨

2. **ä¼˜åŒ–å™¨çŠ¶æ€é‡ç½®**
   - ç»„ä»¶å›æ”¶éœ€è¦æ¸…é™¤ä¼˜åŒ–å™¨åŠ¨é‡
   - **é£é™©ï¼š** å¦‚æœç”¨æˆ·ä½¿ç”¨çš„ä¸æ˜¯ Adam/SGHMCï¼Œå¯èƒ½å¤±è´¥
   - **ç¼“è§£ï¼š** æ·»åŠ  try-except ä¿æŠ¤

3. **å†…å­˜æ¶ˆè€—**
   - Student-t åˆ†å¸ƒéœ€è¦é¢å¤–çš„ `nu` å’Œ `opacity` å‚æ•°
   - **é¢„æœŸå¢åŠ ï¼š** ~20% å†…å­˜

### å›æ»šè®¡åˆ’

å¦‚æœä¿®å¤åæ€§èƒ½ä»å·®ï¼ŒæŒ‰ä»¥ä¸‹é¡ºåºå›æ»šï¼š

1. **ä»…ä¿ç•™ Bug 1-2 ä¿®å¤**ï¼ˆtanh + å¯ç”¨ SSSï¼‰
2. **ç¦ç”¨ç»„ä»¶å›æ”¶**ï¼Œä½¿ç”¨ä¼ ç»Ÿ densification
3. **è°ƒæ•´ Balance Loss æƒé‡**ï¼ˆä» 0.01 å‡å°‘åˆ° 0.001ï¼‰

---

## ç¬¬å…­éƒ¨åˆ†ï¼šåç»­ä¼˜åŒ–

ä¿®å¤å®Œæˆåï¼Œå¯è€ƒè™‘ä»¥ä¸‹ä¼˜åŒ–ï¼š

1. **SGHMC ä¼˜åŒ–å™¨**
   - å®˜æ–¹ä½¿ç”¨ SGHMC è€Œé Adam
   - éœ€è¦åœ¨ `training_setup` ä¸­åˆ‡æ¢

2. **ä¸¤é˜¶æ®µè®­ç»ƒ**
   - Burn-in é˜¶æ®µï¼ˆiter 0-7000ï¼‰ï¼šé«˜å™ªå£° C_burnin
   - ä¸»è®­ç»ƒé˜¶æ®µï¼ˆiter 7000+ï¼‰ï¼šä½å™ªå£° C

3. **Opacity Reset**
   - å®˜æ–¹æ¯ 3000 æ¬¡è¿­ä»£é‡ç½®ä½ opacity ç»„ä»¶
   - åœ¨ `recycle_components` ä¸­é›†æˆ

4. **Scale Regularization**
   - å®˜æ–¹è¿˜æœ‰ `scale_reg * torch.abs(scaling).mean()`
   - å¯æ·»åŠ åˆ°æŸå¤±å‡½æ•°

---

## é™„å½•ï¼šå®˜æ–¹ä»£ç å…³é”®ç‰‡æ®µ

### A. Opacity æ¿€æ´»å‡½æ•°ï¼ˆ`nt_model.py`ï¼‰

```python
class NTModel:
    def __init__(self, ...):
        # Activation functions
        self.opacity_activation = torch.tanh
        self.inverse_opacity_activation = self._inverse_tanh

    def _inverse_tanh(self, x):
        x = torch.clamp(x, -0.99, 0.99)
        return 0.5 * torch.log((1 + x) / (1 - x))

    @property
    def get_opacity(self):
        opacity = self.opacity_activation(self._opacity)
        return torch.clamp(opacity, -1.0 + 1e-5, 1.0 - 1e-5)
```

### B. Balance Lossï¼ˆ`train.py`ï¼‰

```python
# Line 104 in official train.py
loss = (1.0 - opt.lambda_dssim) * Ll1 + opt.lambda_dssim * (1.0 - ssim(...))

# Regularization terms
opacity_reg = args.opacity_reg * torch.abs(primitives.get_opacity).mean()
scale_reg = args.scale_reg * torch.abs(primitives.get_scaling).mean()

loss += opacity_reg + scale_reg
```

### C. ç»„ä»¶å›æ”¶æ ¸å¿ƒé€»è¾‘ï¼ˆ`nt_model.py`ï¼‰

```python
def recycle_components(self):
    # Dead component detection
    alive_mask = self.get_opacity > self.opacity_threshold
    dead_indices = torch.where(~alive_mask)[0]

    # 5% cap
    max_recycle = int(0.05 * self._xyz.shape[0])
    if len(dead_indices) > max_recycle:
        dead_indices = dead_indices[:max_recycle]

    # Resample from alive components
    alive_indices = torch.where(alive_mask)[0]
    weights = self.get_opacity[alive_mask].squeeze()
    sample_indices = torch.multinomial(weights, len(dead_indices), replacement=True)

    # Reinitialize
    self._xyz[dead_indices] = self._xyz[alive_indices[sample_indices]] + noise
    self._opacity[dead_indices] = self.inverse_opacity_activation(torch.ones(...) * 0.5)
```

---

**æ€»ç»“ï¼š**

æœ¬ä¿®å¤æ–¹æ¡ˆåŸºäºå®˜æ–¹ä»£ç çš„æ·±å…¥ç ”ç©¶ï¼Œä¿®å¤äº†ç”¨æˆ·å®ç°çš„ 5 ä¸ªè‡´å‘½ bugï¼š

1. âœ… **Bug 1ï¼š** å¯ç”¨ SSSï¼ˆ`use_student_t = True`ï¼‰
2. âœ… **Bug 2ï¼š** ä¿®æ­£ Opacity æ¿€æ´»å‡½æ•°ï¼ˆ`tanh` æ›¿ä»£ `sigmoid * 1.2 - 0.2`ï¼‰
3. âœ… **Bug 3ï¼š** ç§»é™¤è‡ªåˆ›çš„æ¸è¿›å¼ Scooping é™åˆ¶
4. âœ… **Bug 4ï¼š** ä½¿ç”¨è®ºæ–‡çš„ Balance Lossï¼ˆ`0.01 * |opacity|`ï¼‰
5. âœ… **Bug 5ï¼š** å®ç°ç»„ä»¶å›æ”¶æœºåˆ¶ï¼ˆæ›¿ä»£ä¼ ç»Ÿ densificationï¼‰

é¢„æœŸä¿®å¤åï¼Œæ€§èƒ½å°†ä» **10.60 dB** æ¢å¤åˆ° Baseline **18.99 dB** æˆ–æ›´å¥½ã€‚

**ä¸‹ä¸€æ­¥ï¼š** ç­‰å¾…ç”¨æˆ·ç¡®è®¤åæ‰§è¡Œä¿®å¤ã€‚

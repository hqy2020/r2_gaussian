# DropGaussian Curriculum Drop 实验计划

**实验日期：** 2025-11-19
**实验名称：** `dropgaussian_curriculum`（动态 drop rate，最大值 0.1）
**数据集：** Foot 3-views
**状态：** 📋 待执行

---

## 🎯 实验目标

严格遵循 DropGaussian 原论文，采用动态 drop rate 逐步提高的策略，保证前期训练稳定性，目标超越 Baseline PSNR 28.48。

---

## 📊 策略配置

### **动态 Drop Rate 时间表**

| 迭代区间 | Drop Rate | 策略说明 |
|---------|-----------|---------|
| 0 - 5,000 | 0.0 (0%) | 前期完全不 drop，充分训练 |
| 5,000 - 10,000 | 0.0 - 0.02 (0-2%) | 渐进式增长 |
| 10,000 - 15,000 | 0.02 - 0.04 (2-4%) | 继续增长 |
| 15,000 - 20,000 | 0.04 - 0.06 (4-6%) | 继续增长 |
| 20,000 - 25,000 | 0.06 - 0.08 (6-8%) | 继续增长 |
| 25,000 - 30,000 | 0.08 - 0.10 (8-10%) | 达到最大值 |

### **关键参数**

```python
use_drop_gaussian = True
drop_gamma = 0.1            # 最大 drop rate（比原论文 0.2 降低 50%）
drop_start_iter = 5000      # 开始 drop 的迭代（保证前期稳定）
drop_end_iter = 30000       # 达到最大 drop rate 的迭代
use_importance_aware_drop = False  # 不使用 importance-aware（回归原始论文）
```

---

## 📈 预期结果

### **保守估计（基于降低 drop rate）**

| 指标 | Baseline | 之前 Drop (γ=0.2) | 本次实验 (γ=0.1) | 预期改进 |
|------|----------|-------------------|-----------------|---------|
| **2D PSNR** | 28.48 | 28.17 | **28.45 - 28.55** | ✅ 接近或超越 Baseline |
| **2D SSIM** | 0.900 | 0.898 | **0.899 - 0.902** | ✅ 持平或更好 |
| **3D PSNR** | 23.14 | 22.91 | **23.10 - 23.20** | ✅ 接近 Baseline |

### **乐观估计（基于前期稳定 + 渐进式）**

- **2D PSNR:** 28.50 - 28.60（超越 Baseline）
- 原因：前 5000 轮充分训练 → 更好的 Gaussian 初始化 → 后期 drop 损失更小

---

## 🔍 与之前实验的区别

| 特性 | DropGaussian (γ=0.2) | Importance-Aware | 本次 Curriculum Drop |
|------|---------------------|------------------|---------------------|
| **Drop Rate** | 固定从 0 线性增长到 0.2 | 同左，但保护高 opacity | 前 5000 轮不 drop，之后增长到 0.1 |
| **前期稳定性** | ❌ 从第 1 轮就开始 drop | ❌ 同左 | ✅ 前 5000 轮完全不 drop |
| **最大 Drop Rate** | 20% | 20%（部分保护） | **10%（降低 50%）** |
| **训练信号损失** | 高（20%） | 中（部分保护） | **低（10%）** |
| **复杂度** | 简单 | 复杂（需计算 opacity） | 简单 |

**核心优势：**
✅ 前期稳定训练（5000 轮不 drop）→ 更好的 Gaussian 质量
✅ 降低最大 drop rate（0.1 vs 0.2）→ 减少训练信号损失
✅ 回归原始论文策略（不使用 importance-aware）→ 降低复杂度

---

## 🚀 实验流程

### **1. 代码修改（✅ 已完成）**

- 修改 `r2_gaussian/arguments/__init__.py`：
  - `drop_gamma = 0.1`
  - 新增 `drop_start_iter = 5000`
  - 新增 `drop_end_iter = 30000`

- 修改 `r2_gaussian/gaussian/render_query.py`：
  - 实现三阶段 drop rate 策略（0 → 线性增长 → 稳定）

### **2. 验证（✅ 已完成）**

- 运行 `/tmp/verify_drop_strategy.py` 验证策略正确性
- 生成曲线图 `/tmp/drop_rate_schedule.png`

### **3. 训练（⏳ 待执行）**

```bash
bash scripts/train_dropgaussian_curriculum.sh
```

**预计训练时间：** 约 2-3 小时（30000 轮）

### **4. 监控指标**

实时监控以下指标（每 5000 轮）：
- ✅ PSNR 是否持续上升
- ✅ Gaussian 数量是否稳定
- ✅ Loss 是否收敛

**预警阈值：**
- ❌ 如果 10000 轮 PSNR < 28.0 → 说明策略失效
- ❌ 如果 Gaussian 数量骤减 → 说明 drop rate 仍然过高

---

## 📋 成功标准

### **最低要求（P0）**
- ✅ PSNR ≥ 28.40（不低于之前的 Importance-Aware）
- ✅ 训练过程稳定，无 Gaussian 数量骤减

### **目标要求（P1）**
- ✅ PSNR ≥ 28.48（达到 Baseline 水平）
- ✅ 至少 50% 的图像表现改善

### **理想要求（P2）**
- ✅ PSNR > 28.50（超越 Baseline）
- ✅ 证明 Curriculum Drop + 降低 drop rate 是稀疏场景的正确策略

---

## 🔄 如果失败怎么办？

### **失败场景 A：PSNR < 28.40**
→ 进一步降低 drop_gamma 到 0.05（5%）

### **失败场景 B：前期训练不稳定**
→ 延长 drop_start_iter 到 10000（前 10000 轮不 drop）

### **失败场景 C：后期 drop 损伤仍然过大**
→ 改用非线性增长（如指数增长或分段增长）

---

## 📚 经验总结（待更新）

**训练完成后补充：**
- 实际 PSNR 结果
- 逐图对比分析
- Gaussian 数量变化趋势
- 下一步改进建议

---

**实验准备时间：** 2025-11-19 15:48
**负责人：** Claude Code
**状态：** ✅ 代码就绪，等待启动训练
